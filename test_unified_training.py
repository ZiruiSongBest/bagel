#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€ç”Ÿæˆè®­ç»ƒä»£ç æµ‹è¯•è„šæœ¬

è¿™ä¸ªè„šæœ¬ç”¨äºæµ‹è¯•ç»Ÿä¸€ç”Ÿæˆè®­ç»ƒæ¡†æ¶çš„å„ä¸ªç»„ä»¶ï¼ŒåŒ…æ‹¬ï¼š
1. æ•°æ®å¤„ç†å™¨æµ‹è¯•
2. è®­ç»ƒå™¨é…ç½®æµ‹è¯•  
3. æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤æµ‹è¯•
4. è¯„ä¼°æŒ‡æ ‡æµ‹è¯•
"""

import os
import sys
import json
import torch
import tempfile
from PIL import Image
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from training.unified_data_processor import UnifiedGenerationDataset, UnifiedTrainingExample
from training.unified_trainer import UnifiedTrainingConfig, UnifiedTrainer
from training.evaluation_metrics import UnifiedEvaluator


def create_test_data():
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    print("åˆ›å»ºæµ‹è¯•æ•°æ®...")
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = tempfile.mkdtemp()
    print(f"ä¸´æ—¶ç›®å½•: {temp_dir}")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_images = []
    for i in range(3):
        img = Image.new('RGB', (256, 256), color=(i*80, 100, 150))
        img_path = os.path.join(temp_dir, f"test_image_{i}.jpg")
        img.save(img_path)
        test_images.append(img_path)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = [
        # å¯¹è¯æ ¼å¼
        {
            "conversations": [
                {
                    "role": "user",
                    "type": "text",
                    "content": "è¯·ç”Ÿæˆä¸€å¼ è“è‰²çš„å›¾ç‰‡"
                },
                {
                    "role": "assistant", 
                    "type": "image",
                    "image_path": test_images[0]
                }
            ],
            "metadata": {"task_type": "text_to_image"}
        },
        
        # å›¾åƒæè¿°æ ¼å¼
        {
            "image_path": test_images[1],
            "caption": "è¿™æ˜¯ä¸€å¼ æµ‹è¯•å›¾ç‰‡ï¼Œé¢œè‰²åç»¿è‰²ã€‚",
            "metadata": {"task_type": "image_to_text"}
        },
        
        # ç›´æ¥æ ¼å¼
        {
            "input_sequence": [
                {"type": "text", "content": "ç¼–è¾‘è¿™å¼ å›¾ç‰‡ï¼šæ”¹å˜é¢œè‰²"},
                {"type": "image", "image_path": test_images[2]}
            ],
            "target_sequence": [
                {"type": "image", "image_path": test_images[0]}
            ],
            "metadata": {"task_type": "image_editing"}
        }
    ]
    
    # ä¿å­˜æµ‹è¯•æ•°æ®æ–‡ä»¶
    train_data_path = os.path.join(temp_dir, "train_data.jsonl")
    with open(train_data_path, 'w', encoding='utf-8') as f:
        for item in test_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    return temp_dir, train_data_path, test_images


def test_data_processor():
    """æµ‹è¯•æ•°æ®å¤„ç†å™¨"""
    print("\n" + "="*50)
    print("æµ‹è¯•æ•°æ®å¤„ç†å™¨")
    print("="*50)
    
    try:
        # åˆ›å»ºæ¨¡æ‹Ÿçš„tokenizerå’Œtransforms
        class MockTokenizer:
            def encode(self, text):
                return [1, 2, 3, 4, 5]  # ç®€å•çš„æ¨¡æ‹Ÿç¼–ç 
            
        class MockTransform:
            def __call__(self, image):
                # è¿”å›æ¨¡æ‹Ÿçš„tensor
                return torch.randn(3, 224, 224)
            
            def resize_transform(self, image):
                return torch.randn(3, 224, 224)
        
        tokenizer = MockTokenizer()
        vae_transform = MockTransform()
        vit_transform = MockTransform()
        new_token_ids = {
            'bos_token_id': 1,
            'eos_token_id': 2, 
            'start_of_image': 3,
            'end_of_image': 4
        }
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        temp_dir, train_data_path, test_images = create_test_data()
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = UnifiedGenerationDataset(
            data_path=train_data_path,
            tokenizer=tokenizer,
            vae_transform=vae_transform,
            vit_transform=vit_transform,
            new_token_ids=new_token_ids,
            max_sequence_length=512,
            max_image_tokens=256,
        )
        
        print(f"âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼ŒåŒ…å« {len(dataset)} ä¸ªæ ·æœ¬")
        
        # æµ‹è¯•è·å–æ ·æœ¬
        for i in range(min(2, len(dataset))):
            sample = dataset[i]
            print(f"æ ·æœ¬ {i}:")
            print(f"  åºåˆ—é•¿åº¦: {sample['sequence_length']}")
            print(f"  æ–‡æœ¬tokens: {len(sample['packed_text_ids'])}")
            print(f"  è¾“å…¥é•¿åº¦: {sample['input_length']}")
            print(f"  ç›®æ ‡é•¿åº¦: {sample['target_length']}")
            print(f"  å…ƒæ•°æ®: {sample['metadata']}")
        
        print("âœ… æ•°æ®å¤„ç†å™¨æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®å¤„ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_training_config():
    """æµ‹è¯•è®­ç»ƒé…ç½®"""
    print("\n" + "="*50)
    print("æµ‹è¯•è®­ç»ƒé…ç½®")
    print("="*50)
    
    try:
        config = UnifiedTrainingConfig(
            train_data_path="/fake/path/train.jsonl",
            val_data_path="/fake/path/val.jsonl",
            output_dir="./test_outputs",
            batch_size=1,
            gradient_accumulation_steps=4,
            num_epochs=2,
            learning_rate=1e-5,
            text_loss_weight=1.0,
            image_loss_weight=1.0,
        )
        
        print("âœ… è®­ç»ƒé…ç½®åˆ›å»ºæˆåŠŸ")
        print("é…ç½®å‚æ•°:")
        config_dict = config.to_dict()
        for key, value in list(config_dict.items())[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªå‚æ•°
            print(f"  {key}: {value}")
        print("  ...")
        
        return True
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒé…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_evaluation_metrics():
    """æµ‹è¯•è¯„ä¼°æŒ‡æ ‡"""
    print("\n" + "="*50)
    print("æµ‹è¯•è¯„ä¼°æŒ‡æ ‡")
    print("="*50)
    
    try:
        # åˆ›å»ºè¯„ä¼°å™¨
        evaluator = UnifiedEvaluator()
        
        # åˆ›å»ºæ¨¡æ‹Ÿçš„è¯„ä¼°æ•°æ®
        test_results = [
            {
                "input_sequence": ["ç”Ÿæˆä¸€å¼ çŒ«çš„å›¾ç‰‡"],
                "target_sequence": ["è¿™æ˜¯ä¸€å¼ å¯çˆ±çš„å°çŒ«å›¾ç‰‡"],
                "generated_sequence": ["è¿™æ˜¯ä¸€å¼ çŒ«çš„å›¾ç‰‡"],
                "input_types": ["text"],
                "target_types": ["text"],
            },
            {
                "input_sequence": [Image.new('RGB', (256, 256), 'blue')],
                "target_sequence": [Image.new('RGB', (256, 256), 'red')],
                "generated_sequence": [Image.new('RGB', (256, 256), 'green')],
                "input_types": ["image"],
                "target_types": ["image"],
            }
        ]
        
        # è¿è¡Œè¯„ä¼°
        with tempfile.TemporaryDirectory() as temp_dir:
            metrics = evaluator.evaluate_generation_results(
                results=test_results,
                output_dir=temp_dir
            )
        
        print("âœ… è¯„ä¼°æŒ‡æ ‡è®¡ç®—æˆåŠŸ")
        print("è¯„ä¼°ç»“æœ:")
        for key, value in metrics.items():
            if isinstance(value, float):
                print(f"  {key}: {value:.4f}")
            else:
                print(f"  {key}: {value}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°æŒ‡æ ‡æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_mock_training_step():
    """æµ‹è¯•æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤"""
    print("\n" + "="*50)
    print("æµ‹è¯•æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤")
    print("="*50)
    
    try:
        # è¿™é‡Œåªæµ‹è¯•è®­ç»ƒå™¨çš„åˆå§‹åŒ–ï¼Œä¸è¿›è¡ŒçœŸå®çš„æ¨¡å‹è®­ç»ƒ
        # å› ä¸ºéœ€è¦å®Œæ•´çš„BAGELæ¨¡å‹
        
        class MockModel:
            def __init__(self):
                self.device = torch.device('cpu')
                self.linear = torch.nn.Linear(10, 10)  # æ·»åŠ ä¸€ä¸ªå®é™…çš„å±‚
                
            def parameters(self):
                return self.linear.parameters()
                
            def named_parameters(self):
                return self.linear.named_parameters()
                
            def to(self, device):
                self.linear.to(device)
                return self
                
            def train(self):
                self.linear.train()
                
            def eval(self):
                self.linear.eval()
        
        class MockVAEModel:
            def to(self, device):
                return self
                
            def encode(self, x):
                return torch.randn(1, 16, 32, 32)
        
        class MockTokenizer:
            def encode(self, text):
                return [1, 2, 3, 4, 5]
        
        class MockTransform:
            def __call__(self, image):
                return torch.randn(3, 224, 224)
                
            def resize_transform(self, image):
                return torch.randn(3, 512, 512)
        
        # åˆ›å»ºæ¨¡æ‹Ÿç»„ä»¶
        model = MockModel()
        vae_model = MockVAEModel()
        tokenizer = MockTokenizer()
        vae_transform = MockTransform()
        vit_transform = MockTransform()
        new_token_ids = {
            'bos_token_id': 1,
            'eos_token_id': 2, 
            'start_of_image': 3,
            'end_of_image': 4
        }
        
        config = UnifiedTrainingConfig(
            train_data_path="/fake/path",
            output_dir="./test_outputs",
            batch_size=1,
            num_epochs=1,
        )
        
        # åˆ›å»ºè®­ç»ƒå™¨ï¼ˆä¸è¿›è¡Œå®é™…è®­ç»ƒï¼‰
        trainer = UnifiedTrainer(
            model=model,
            vae_model=vae_model,
            tokenizer=tokenizer,
            vae_transform=vae_transform,
            vit_transform=vit_transform,
            new_token_ids=new_token_ids,
            config=config,
        )
        
        print("âœ… è®­ç»ƒå™¨åˆå§‹åŒ–æˆåŠŸ")
        print(f"ä¼˜åŒ–å™¨: {type(trainer.optimizer).__name__}")
        print(f"è®¾å¤‡: {trainer.device}")
        print(f"å…¨å±€æ­¥æ•°: {trainer.global_step}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª ç»Ÿä¸€ç”Ÿæˆè®­ç»ƒä»£ç æµ‹è¯•")
    print("="*60)
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        ("æ•°æ®å¤„ç†å™¨", test_data_processor),
        ("è®­ç»ƒé…ç½®", test_training_config),
        ("è¯„ä¼°æŒ‡æ ‡", test_evaluation_metrics),
        ("æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤", test_mock_training_step),
    ]
    
    results = {}
    for test_name, test_func in tests:
        try:
            results[test_name] = test_func()
        except Exception as e:
            print(f"âŒ {test_name}æµ‹è¯•å‡ºç°å¼‚å¸¸: {e}")
            results[test_name] = False
    
    # æ€»ç»“ç»“æœ
    print("\n" + "="*60)
    print("ğŸ æµ‹è¯•ç»“æœæ€»ç»“")
    print("="*60)
    
    passed = 0
    total = len(tests)
    
    for test_name, passed_test in results.items():
        status = "âœ… é€šè¿‡" if passed_test else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
        if passed_test:
            passed += 1
    
    print(f"\næ€»è®¡: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼è®­ç»ƒä»£ç åŸºæœ¬åŠŸèƒ½æ­£å¸¸ã€‚")
        print("\næ¥ä¸‹æ¥ä½ å¯ä»¥:")
        print("1. å‡†å¤‡çœŸå®çš„è®­ç»ƒæ•°æ®")
        print("2. è¿è¡Œ train_unified_generation.py å¼€å§‹è®­ç»ƒ")
        print("3. å‚è€ƒ training/README_training.md äº†è§£æ›´å¤šç»†èŠ‚")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç æˆ–ä¾èµ–åº“ã€‚")
    
    print("="*60)


if __name__ == "__main__":
    main()
