#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿè¿‡æ‹Ÿåˆæµ‹è¯• - ä¸“é—¨æµ‹è¯•æ‚¨è®­ç»ƒçš„æ–‡æœ¬+å›¾åƒæ•°æ®

ä½¿ç”¨æ–¹æ³•ï¼š
python quick_overfitting_test.py
"""

import os
import sys
import torch
import json
from PIL import Image
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
sys.path.insert(0, str(Path(__file__).parent))

from inference_unified_autoregressive import create_inference_engine


def load_actual_training_samples():
    """åŠ è½½å®é™…çš„è®­ç»ƒæ ·æœ¬ - ä½¿ç”¨ä¸è®­ç»ƒå®Œå…¨ç›¸åŒçš„æ•°æ®å¤„ç†æµç¨‹"""
    print("ğŸ“‚ æ­£åœ¨åŠ è½½å®é™…è®­ç»ƒæ•°æ®...")
    
    # å®é™…è®­ç»ƒæ•°æ®è·¯å¾„
    training_data_path = "/workspace/bagel/dataset/demo/demo_sample/anno.json"
    
    if not os.path.exists(training_data_path):
        print(f"âŒ è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {training_data_path}")
        return None
    
    print(f"âœ… æ‰¾åˆ°è®­ç»ƒæ•°æ®: {training_data_path}")
    
    # ä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„æ•°æ®å¤„ç†å™¨è§£ææ•°æ®
    try:
        from training.unified_data_processor import UnifiedGenerationDataset
        from data.data_utils import add_special_tokens
        from modeling.qwen2 import Qwen2Tokenizer
        from data.transforms import ImageTransform
        
        # åŠ è½½tokenizerå’Œç‰¹æ®Štokensï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼‰
        tokenizer = Qwen2Tokenizer.from_pretrained("/workspace/bagel/models/Qwen2.5-0.5B-Instruct")
        tokenizer, new_token_ids, num_new_tokens = add_special_tokens(tokenizer)
        
        # åˆ›å»ºå›¾åƒå˜æ¢ï¼ˆç”¨äºæµ‹è¯•ï¼Œä¸éœ€è¦å®é™…å˜æ¢ï¼‰
        class DummyTransform:
            def __call__(self, img):
                return torch.zeros((3, 224, 224))  # å ä½ç¬¦
        
        vae_transform = DummyTransform()
        vit_transform = DummyTransform()
        
        # åˆ›å»ºæ•°æ®é›†å¯¹è±¡æ¥è§£ææ•°æ®
        dataset = UnifiedGenerationDataset(
            data_path=training_data_path,
            tokenizer=tokenizer,
            vae_transform=vae_transform,
            vit_transform=vit_transform,
            new_token_ids=new_token_ids,
            max_sequence_length=2048
        )
        
        # è·å–å‰3ä¸ªè§£æåçš„è®­ç»ƒæ ·æœ¬
        training_samples = dataset.examples[:3]
        
        print(f"ğŸ“Š æˆåŠŸè§£æäº† {len(training_samples)} ä¸ªè®­ç»ƒæ ·æœ¬")
        print("âœ… ä½¿ç”¨äº†ä¸è®­ç»ƒå®Œå…¨ç›¸åŒçš„æ•°æ®å¤„ç†æµç¨‹")
        
        return training_samples
        
    except Exception as e:
        print(f"âŒ ä½¿ç”¨è®­ç»ƒæ•°æ®å¤„ç†å™¨å¤±è´¥: {e}")
        print("ğŸ”„ å›é€€åˆ°ç›´æ¥è¯»å–åŸå§‹æ•°æ®...")
        
        # å›é€€ï¼šç›´æ¥è¯»å–åŸå§‹æ•°æ®
        try:
            with open(training_data_path, 'r', encoding='utf-8') as f:
                raw_data = json.load(f)
                print(f"ğŸ“Š ç›´æ¥åŠ è½½äº† {len(raw_data[:3])} ä¸ªåŸå§‹è®­ç»ƒæ ·æœ¬")
                return raw_data[:3]
        except Exception as e2:
            print(f"âŒ ç›´æ¥è¯»å–æ•°æ®ä¹Ÿå¤±è´¥: {e2}")
            return None


def convert_training_sample_to_test_case(sample):
    """å°†è®­ç»ƒæ ·æœ¬è½¬æ¢ä¸ºæµ‹è¯•ç”¨ä¾‹æ ¼å¼"""
    # æ£€æŸ¥æ˜¯å¦æ˜¯UnifiedTrainingExampleå¯¹è±¡
    if hasattr(sample, 'input_sequence') and hasattr(sample, 'target_sequence'):
        # è¿™æ˜¯UnifiedTrainingExampleå¯¹è±¡
        input_text = ""
        expected_output = ""
        
        # å¤„ç†è¾“å…¥åºåˆ—
        for item, item_type in zip(sample.input_sequence, sample.input_types):
            if item_type == 'text':
                input_text += str(item) + " "
            elif item_type == 'image':
                input_text += "[å›¾åƒ] "
        
        # å¤„ç†ç›®æ ‡åºåˆ—
        for item, item_type in zip(sample.target_sequence, sample.target_types):
            if item_type == 'text':
                expected_output += str(item) + " "
            elif item_type == 'image':
                expected_output += "[åº”ç”Ÿæˆå›¾åƒ] "
        
        # è‡ªåŠ¨æ·»åŠ vision tokensåˆ°è¾“å…¥æ–‡æœ¬ï¼ˆå¦‚æœç›®æ ‡åŒ…å«å›¾åƒï¼‰
        if 'image' in sample.target_types and '<|vision_start|>' not in input_text:
            input_text = input_text.strip() + " <|vision_start|><|vision_end|>"
        
        return {
            "input": input_text.strip(),
            "expected": expected_output.strip(),
            "original_sample": sample
        }
    
    elif isinstance(sample, dict):
        # åŸå§‹æ•°æ®æ ¼å¼ï¼ˆmessages + imagesï¼‰
        input_text = ""
        expected_output = ""
        
        if "messages" in sample:
            messages = sample["messages"]
            for message in messages:
                role = message.get('role', '')
                content = message.get('content', '')
                
                if role == 'user':
                    input_text += content + " "
                elif role == 'assistant':
                    expected_output += content + " "
            
            # å¦‚æœassistantçš„å›ç­”åŒ…å«<image>æ ‡è®°ï¼Œè‡ªåŠ¨æ·»åŠ vision tokensåˆ°è¾“å…¥
            if '<image>' in expected_output and '<|vision_start|>' not in input_text:
                input_text = input_text.strip() + " <|vision_start|><|vision_end|>"
        
        return {
            "input": input_text.strip(),
            "expected": expected_output.strip(),
            "original_sample": sample
        }
    
    else:
        # å¦‚æœæ˜¯å…¶ä»–æ ¼å¼
        return {
            "input": str(sample),
            "expected": "æœªçŸ¥æ ¼å¼çš„è®­ç»ƒæ ·æœ¬",
            "original_sample": sample
        }


def quick_overfitting_test():
    """å¿«é€Ÿè¿‡æ‹Ÿåˆæµ‹è¯•"""
    print("ğŸ§ª å¿«é€Ÿè¿‡æ‹Ÿåˆæµ‹è¯•")
    print("æµ‹è¯•æ‚¨è®­ç»ƒçš„æ–‡æœ¬+å›¾åƒæ¨¡å‹æ˜¯å¦æ­£ç¡®å­¦ä¼šäº†è®­ç»ƒæ•°æ®")
    print("-" * 50)
    
    # æ£€æŸ¥ç‚¹è·¯å¾„
    checkpoint_path = "/workspace/bagel/results/unified_training_20250910_201937/checkpoints/0000800"
    
    if not os.path.exists(checkpoint_path):
        print(f"âŒ æ£€æŸ¥ç‚¹ä¸å­˜åœ¨: {checkpoint_path}")
        return False
    
    # åŠ è½½å®é™…è®­ç»ƒæ ·æœ¬
    training_samples = load_actual_training_samples()
    if training_samples is None:
        print("ä½¿ç”¨é»˜è®¤æµ‹è¯•æ ·æœ¬ï¼ˆå¯èƒ½ä¸è®­ç»ƒæ•°æ®ä¸ä¸€è‡´ï¼‰")
        test_cases = [
            {
                "input": "ç”»ä¸€åªå¯çˆ±çš„å°çŒ«åœ¨èŠ±å›­é‡Œç©è€",
                "expected": "åº”è¯¥ç”Ÿæˆæè¿°æ–‡æœ¬å’Œä¸€å¼ çŒ«çš„å›¾åƒ",
                "original_sample": None
            }
        ]
    else:
        print("âœ… ä½¿ç”¨å®é™…è®­ç»ƒæ ·æœ¬è¿›è¡Œè¿‡æ‹Ÿåˆæµ‹è¯•")
        test_cases = [convert_training_sample_to_test_case(sample) for sample in training_samples]
    
    try:
        # åŠ è½½æ¨¡å‹
        print("ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹...")
        engine = create_inference_engine(checkpoint_path)
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
        
        success_count = 0
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\nğŸ¯ æµ‹è¯•ç”¨ä¾‹ {i}/{len(test_cases)}")
            print(f"è¾“å…¥: {test_case['input']}")
            print(f"æœŸæœ›: {test_case['expected']}")
            
            # å¦‚æœæœ‰åŸå§‹è®­ç»ƒæ ·æœ¬ï¼Œæ˜¾ç¤ºæ›´å¤šè¯¦ç»†ä¿¡æ¯
            if test_case.get('original_sample'):
                print("ğŸ“‹ åŸå§‹è®­ç»ƒæ ·æœ¬:")
                original = test_case['original_sample']
                
                # å¦‚æœæ˜¯UnifiedTrainingExampleå¯¹è±¡
                if hasattr(original, 'input_sequence'):
                    print(f"  è¾“å…¥åºåˆ—ç±»å‹: {original.input_types}")
                    print(f"  ç›®æ ‡åºåˆ—ç±»å‹: {original.target_types}")
                    print(f"  è¾“å…¥åºåˆ—é•¿åº¦: {len(original.input_sequence)}")
                    print(f"  ç›®æ ‡åºåˆ—é•¿åº¦: {len(original.target_sequence)}")
                    
                    # æ˜¾ç¤ºæ–‡æœ¬å†…å®¹
                    for i, (item, item_type) in enumerate(zip(original.input_sequence, original.input_types)):
                        if item_type == 'text':
                            print(f"  è¾“å…¥æ–‡æœ¬{i+1}: {str(item)[:80]}{'...' if len(str(item)) > 80 else ''}")
                    
                    for i, (item, item_type) in enumerate(zip(original.target_sequence, original.target_types)):
                        if item_type == 'text':
                            print(f"  ç›®æ ‡æ–‡æœ¬{i+1}: {str(item)[:80]}{'...' if len(str(item)) > 80 else ''}")
                        elif item_type == 'image':
                            print(f"  ç›®æ ‡å›¾åƒ{i+1}: [å›¾åƒå¯¹è±¡]")
                
                # å¦‚æœæ˜¯åŸå§‹å­—å…¸æ ¼å¼
                elif isinstance(original, dict):
                    for key, value in original.items():
                        if isinstance(value, (list, dict)):
                            print(f"  {key}: {str(value)[:100]}{'...' if len(str(value)) > 100 else ''}")
                        else:
                            print(f"  {key}: {value}")
                else:
                    print(f"  åŸå§‹æ ·æœ¬: {str(original)[:100]}{'...' if len(str(original)) > 100 else ''}")
            
            try:
                # è¿›è¡Œæ¨ç† - ä½¿ç”¨ä½æ¸©åº¦ç¡®ä¿ç¡®å®šæ€§ç»“æœï¼ˆæµ‹è¯•è¿‡æ‹Ÿåˆï¼‰
                results = engine.autoregressive_generate(
                    prompt=test_case['input'],
                    max_length=200,
                    do_sample=True,
                    temperature=0.1,  # å¾ˆä½çš„æ¸©åº¦ï¼Œæ¥è¿‘ç¡®å®šæ€§
                    image_shapes=(512, 512),
                    cfg_text_scale=2.0,  # è¾ƒä½çš„CFGé¿å…è¿‡åº¦åç¦»è®­ç»ƒæ•°æ®
                    cfg_img_scale=1.2,
                    num_timesteps=20,  # è¾ƒå°‘æ­¥æ•°åŠ å¿«æµ‹è¯•
                    save_intermediate=True,
                    output_dir=f"quick_test_case_{i}"
                )
                
                # åˆ†æç»“æœ
                text_outputs = []
                image_outputs = []
                
                for item in results:
                    if isinstance(item, str):
                        text_outputs.append(item)
                    elif hasattr(item, 'save'):  # PIL Image
                        image_outputs.append(item)
                
                print(f"ğŸ“Š ç»“æœåˆ†æ:")
                print(f"  ç”Ÿæˆæ–‡æœ¬æ•°: {len(text_outputs)}")
                print(f"  ç”Ÿæˆå›¾åƒæ•°: {len(image_outputs)}")
                
                # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡æœ¬
                for j, text in enumerate(text_outputs):
                    print(f"  æ–‡æœ¬{j+1}: {text[:80]}{'...' if len(text) > 80 else ''}")
                
                # ä¿å­˜å›¾åƒ
                for j, img in enumerate(image_outputs):
                    img_path = f"quick_test_case_{i}_image_{j+1}.png"
                    img.save(img_path)
                    print(f"  å›¾åƒ{j+1}: å·²ä¿å­˜åˆ° {img_path} (å°ºå¯¸: {img.size})")
                
                # åˆ¤æ–­æ˜¯å¦æˆåŠŸï¼ˆæœ‰ç”Ÿæˆå†…å®¹å³è®¤ä¸ºæˆåŠŸï¼‰
                if len(text_outputs) > 0 or len(image_outputs) > 0:
                    print("âœ… æµ‹è¯•æˆåŠŸ - æ¨¡å‹ç”Ÿæˆäº†å†…å®¹")
                    success_count += 1
                    
                    # ç‰¹åˆ«æ£€æŸ¥å›¾åƒç”Ÿæˆï¼ˆè¿™æ˜¯å…³é”®æµ‹è¯•ç‚¹ï¼‰
                    if len(image_outputs) > 0:
                        print("ğŸ¨ âœ… æ¨¡å‹æˆåŠŸç”Ÿæˆäº†å›¾åƒï¼ˆè¿‡æ‹Ÿåˆç›®æ ‡è¾¾æˆï¼‰")
                    else:
                        print("ğŸ“ æ¨¡å‹åªç”Ÿæˆäº†æ–‡æœ¬ï¼Œæœªç”Ÿæˆå›¾åƒ")
                else:
                    print("âŒ æµ‹è¯•å¤±è´¥ - æ¨¡å‹æœªç”Ÿæˆä»»ä½•å†…å®¹")
                
            except Exception as e:
                print(f"âŒ æµ‹è¯•ç”¨ä¾‹ {i} å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        # æ€»ç»“
        print(f"\n{'='*50}")
        print("ğŸ¯ è¿‡æ‹Ÿåˆæµ‹è¯•æ€»ç»“")
        print(f"{'='*50}")
        print(f"æˆåŠŸæµ‹è¯•ç”¨ä¾‹: {success_count}/3")
        print(f"æˆåŠŸç‡: {success_count/3*100:.1f}%")
        
        if success_count == 3:
            print(" æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
  
        elif success_count > 0:
            print("âš ï¸  éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œæ¨¡å‹éƒ¨åˆ†å­¦ä¼šäº†è®­ç»ƒæ¨¡å¼ã€‚")
        else:
            print("âŒ æ‰€æœ‰æµ‹è¯•å¤±è´¥ï¼Œæ¨¡å‹å¯èƒ½æœªæ­£ç¡®å­¦ä¹ è®­ç»ƒæ•°æ®ã€‚")
            print("å»ºè®®æ£€æŸ¥:")
            print("  1. æ£€æŸ¥ç‚¹æ˜¯å¦æ­£ç¡®")
            print("  2. æ¨¡å‹é…ç½®æ˜¯å¦åŒ¹é…è®­ç»ƒæ—¶çš„è®¾ç½®")
            print("  3. ç‰¹æ®Štokenæ˜¯å¦æ­£ç¡®è®¾ç½®")
        
        return success_count > 0
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_special_tokens():
    """å¿«é€Ÿæµ‹è¯•ç‰¹æ®Štoken"""
    print("\nğŸ” æ£€æŸ¥ç‰¹æ®Štokenè®¾ç½®")
    print("-" * 30)
    
    try:
        from data.data_utils import add_special_tokens
        from modeling.qwen2 import Qwen2Tokenizer
        
        # åŠ è½½tokenizer
        tokenizer = Qwen2Tokenizer.from_pretrained("/workspace/bagel/models/Qwen2.5-0.5B-Instruct")
        tokenizer, new_token_ids, num_new_tokens = add_special_tokens(tokenizer)
        
        print(f"æ–°å¢ç‰¹æ®Štokenæ•°é‡: {num_new_tokens}")
        
        # æ˜¾ç¤ºå›¾åƒç›¸å…³çš„ç‰¹æ®Štoken
        image_tokens = {k: v for k, v in new_token_ids.items() 
                       if 'image' in k.lower() or 'vision' in k.lower()}
        
        print("å›¾åƒç›¸å…³ç‰¹æ®Štoken:")
        for token_name, token_id in image_tokens.items():
            token_text = tokenizer.decode([token_id])
            print(f"  {token_name}: ID={token_id}, Text='{token_text}'")
        
        # æµ‹è¯•ç¼–ç 
        test_text = "è¿™æ˜¯æ–‡æœ¬ <|vision_start|> è¿™é‡Œæ˜¯å›¾åƒ <|vision_end|> æ›´å¤šæ–‡æœ¬"
        encoded = tokenizer.encode(test_text)
        print(f"\næµ‹è¯•ç¼–ç : {test_text}")
        print(f"ç¼–ç ç»“æœé•¿åº¦: {len(encoded)}")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç‰¹æ®Štoken
        found_special = []
        for token_id in encoded:
            if token_id in new_token_ids.values():
                token_name = [k for k, v in new_token_ids.items() if v == token_id][0]
                found_special.append(token_name)
        
        if found_special:
            print(f"âœ… å‘ç°ç‰¹æ®Štoken: {found_special}")
        else:
            print("âš ï¸  æœªå‘ç°ç‰¹æ®Štoken")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç‰¹æ®Štokenæµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å¿«é€Ÿè¿‡æ‹Ÿåˆæµ‹è¯•")
    print("è¿™ä¸ªæµ‹è¯•ä¸“é—¨éªŒè¯æ‚¨è®­ç»ƒçš„æ–‡æœ¬+å›¾åƒæ¨¡å‹")
    print("=" * 60)
    
    # æ£€æŸ¥GPU
    if torch.cuda.is_available():
        print(f"ğŸ”¥ ä½¿ç”¨GPU: {torch.cuda.get_device_name()}")
    else:
        print("âš ï¸  ä½¿ç”¨CPUï¼ˆä¼šæ¯”è¾ƒæ…¢ï¼‰")
    
    # æµ‹è¯•ç‰¹æ®Štoken
    token_test_ok = test_special_tokens()
    
    # ä¸»è¦è¿‡æ‹Ÿåˆæµ‹è¯•
    main_test_ok = quick_overfitting_test()
    
    print(f"\n{'='*60}")
    print("ğŸ æœ€ç»ˆç»“æœ")
    print(f"{'='*60}")
    
    if token_test_ok and main_test_ok:
        print("ğŸ‰ è¿‡æ‹Ÿåˆæµ‹è¯•æˆåŠŸï¼")
        print("æ‚¨çš„æ¨¡å‹æ­£ç¡®å­¦ä¹ äº†è®­ç»ƒæ•°æ®çš„æ¨¡å¼")
        print("ğŸ“‚ ç”Ÿæˆçš„å›¾åƒå·²ä¿å­˜åœ¨å½“å‰ç›®å½•")
    else:
        print("âŒ æµ‹è¯•ä¸­å­˜åœ¨é—®é¢˜")
        if not token_test_ok:
            print("  - ç‰¹æ®Štokené…ç½®å¯èƒ½æœ‰é—®é¢˜")
        if not main_test_ok:
            print("  - æ¨¡å‹ç”Ÿæˆæµ‹è¯•å¤±è´¥")
        print("å»ºè®®æ£€æŸ¥æ¨¡å‹å’Œé…ç½®")


if __name__ == "__main__":
    main()
