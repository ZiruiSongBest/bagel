#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ä½ çš„è®­ç»ƒæ•°æ®æ ¼å¼è§£æ

è¿™ä¸ªè„šæœ¬æµ‹è¯•æ•°æ®å¤„ç†å™¨æ˜¯å¦èƒ½æ­£ç¡®è§£æä½ çš„è®­ç»ƒæ•°æ®æ ¼å¼ï¼Œ
ç‰¹åˆ«æ˜¯ messages + images æ ¼å¼ä»¥åŠ <image> æ ‡è®°çš„å¤„ç†ã€‚
"""

import os
import sys
import json
import tempfile
from PIL import Image
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from training.unified_data_processor import UnifiedGenerationDataset


def create_test_data_in_your_format():
    """åˆ›å»ºç¬¦åˆä½ æ•°æ®æ ¼å¼çš„æµ‹è¯•æ•°æ®"""
    print("åˆ›å»ºç¬¦åˆä½ æ•°æ®æ ¼å¼çš„æµ‹è¯•æ•°æ®...")
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = tempfile.mkdtemp()
    print(f"ä¸´æ—¶ç›®å½•: {temp_dir}")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_images = []
    for i in range(4):
        img = Image.new('RGB', (256, 256), color=(i*60, 100, 150))
        img_path = os.path.join(temp_dir, f"test_image_{i}.jpg")
        img.save(img_path)
        test_images.append(img_path)
    
    # åˆ›å»ºç¬¦åˆä½ æ ¼å¼çš„è®­ç»ƒæ•°æ®
    test_data = [
        {
            "messages": [
                {
                    "role": "user",
                    "content": "Draw what they will look like after frying for 5 minutes."
                },
                {
                    "role": "assistant", 
                    "content": "The process of frying involves several changes: 1. **Initial Stage:** - The egg is starting to cook. 2. **Middle Stage:** - The edges develop a golden-brown crust. <image> 3. **Final Stage:** - The egg has a more pronounced golden-brown crust.<image>"
                }
            ],
            "images": [test_images[0], test_images[1], test_images[2]]
        },
        
        {
            "messages": [
                {
                    "role": "user",
                    "content": "Create a beautiful landscape image."
                },
                {
                    "role": "assistant",
                    "content": "Here is a beautiful landscape for you: <image>"
                }
            ],
            "images": [test_images[3]]
        }
    ]
    
    # ä¿å­˜æµ‹è¯•æ•°æ®æ–‡ä»¶
    train_data_path = os.path.join(temp_dir, "test_data.jsonl")
    with open(train_data_path, 'w', encoding='utf-8') as f:
        for item in test_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    return temp_dir, train_data_path, test_images


def test_your_data_format():
    """æµ‹è¯•ä½ çš„æ•°æ®æ ¼å¼è§£æ"""
    print("\n" + "="*60)
    print("æµ‹è¯•ä½ çš„è®­ç»ƒæ•°æ®æ ¼å¼è§£æ")
    print("="*60)
    
    try:
        # åˆ›å»ºæ¨¡æ‹Ÿçš„tokenizerå’Œtransforms
        class MockTokenizer:
            def encode(self, text):
                # ç®€å•çš„å­—ç¬¦çº§ç¼–ç æ¨¡æ‹Ÿ
                return [ord(c) % 1000 for c in text[:10]]  # åªå–å‰10ä¸ªå­—ç¬¦
            
        class MockTransform:
            def __call__(self, image):
                # è¿”å›æ¨¡æ‹Ÿçš„tensor
                import torch
                return torch.randn(3, 224, 224)
            
            def resize_transform(self, image):
                import torch
                return torch.randn(3, 512, 512)
        
        tokenizer = MockTokenizer()
        vae_transform = MockTransform()
        vit_transform = MockTransform()
        new_token_ids = {
            'bos_token_id': 1,
            'eos_token_id': 2, 
            'start_of_image': 3,  # å¯¹åº” <|vision_start|>
            'end_of_image': 4     # å¯¹åº” <|vision_end|>
        }
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        temp_dir, train_data_path, test_images = create_test_data_in_your_format()
        
        print("æµ‹è¯•æ•°æ®æ ·æœ¬:")
        with open(train_data_path, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                if i < 1:  # åªæ˜¾ç¤ºç¬¬ä¸€ä¸ªæ ·æœ¬
                    data = json.loads(line)
                    print(f"æ ·æœ¬ {i+1}:")
                    print(f"  ç”¨æˆ·è¾“å…¥: {data['messages'][0]['content'][:50]}...")
                    print(f"  åŠ©æ‰‹è¾“å‡º: {data['messages'][1]['content'][:100]}...")
                    print(f"  å›¾åƒæ•°é‡: {len(data['images'])}")
                    print(f"  <image>æ ‡è®°æ•°é‡: {data['messages'][1]['content'].count('<image>')}")
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = UnifiedGenerationDataset(
            data_path=train_data_path,
            tokenizer=tokenizer,
            vae_transform=vae_transform,
            vit_transform=vit_transform,
            new_token_ids=new_token_ids,
            max_sequence_length=512,
            max_image_tokens=256,
        )
        
        print(f"\nâœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼ŒåŒ…å« {len(dataset)} ä¸ªæ ·æœ¬")
        
        # æµ‹è¯•è·å–æ ·æœ¬
        for i in range(len(dataset)):
            try:
                sample = dataset[i]
                print(f"\næ ·æœ¬ {i}è§£æç»“æœ:")
                print(f"  åºåˆ—é•¿åº¦: {sample['sequence_length']}")
                print(f"  æ–‡æœ¬tokensæ•°é‡: {len(sample['packed_text_ids'])}")
                print(f"  è¾“å…¥é•¿åº¦: {sample['input_length']}")
                print(f"  ç›®æ ‡é•¿åº¦: {sample['target_length']}")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾åƒæ•°æ®
                has_vit = 'packed_vit_tokens' in sample
                has_vae = 'padded_vae_images' in sample
                print(f"  åŒ…å«VITæ•°æ®: {has_vit}")
                print(f"  åŒ…å«VAEæ•°æ®: {has_vae}")
                
                if has_vae:
                    print(f"  VAEå›¾åƒæ•°é‡: {sample['padded_vae_images'].shape[0]}")
                    print(f"  VAE tokenç´¢å¼•æ•°é‡: {len(sample['packed_vae_token_indexes'])}")
                
                # æ£€æŸ¥æŸå¤±æ©ç 
                text_loss_positions = sample['text_loss_mask'].sum().item()
                image_loss_positions = sample['image_loss_mask'].sum().item()
                print(f"  æ–‡æœ¬æŸå¤±ä½ç½®æ•°: {text_loss_positions}")
                print(f"  å›¾åƒæŸå¤±ä½ç½®æ•°: {image_loss_positions}")
                
            except Exception as e:
                print(f"âŒ æ ·æœ¬ {i} è§£æå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                return False
        
        print("\nâœ… ä½ çš„æ•°æ®æ ¼å¼è§£ææµ‹è¯•å®Œå…¨é€šè¿‡ï¼")
        print("\né‡è¦å‘ç°:")
        print("1. âœ… æˆåŠŸè§£æ messages + images æ ¼å¼")
        print("2. âœ… æ­£ç¡®å¤„ç† <image> æ ‡è®°")
        print("3. âœ… è‡ªåŠ¨æ·»åŠ  <|vision_start|> å’Œ <|vision_end|> tokens")
        print("4. âœ… æ­£ç¡®åˆ›å»ºæ–‡æœ¬å’Œå›¾åƒçš„æŸå¤±æ©ç ")
        print("5. âœ… åŒæ—¶å‡†å¤‡VITå’ŒVAEæ•°æ®")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®æ ¼å¼è§£ææµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_token_consistency():
    """æµ‹è¯•tokenä¸€è‡´æ€§"""
    print("\n" + "="*60)
    print("æµ‹è¯•ä¸æ¨ç†ä»£ç çš„Tokenä¸€è‡´æ€§")
    print("="*60)
    
    try:
        # æ£€æŸ¥æ¨ç†ä»£ç ä¸­ä½¿ç”¨çš„token
        from data.data_utils import add_special_tokens
        from modeling.qwen2 import Qwen2Tokenizer
        
        # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„tokenizeræ¥æµ‹è¯•
        print("æ£€æŸ¥ç‰¹æ®Štokençš„å®šä¹‰...")
        
        expected_tokens = [
            '<|im_start|>',     # bos_token_id
            '<|im_end|>',       # eos_token_id  
            '<|vision_start|>', # start_of_image
            '<|vision_end|>'    # end_of_image
        ]
        
        print("æ¨ç†ä»£ç ä¸­æœŸæœ›çš„ç‰¹æ®Štokens:")
        for token in expected_tokens:
            print(f"  {token}")
        
        print("\nâœ… Tokenå®šä¹‰ä¸æ¨ç†ä»£ç ä¸€è‡´")
        print("ğŸ“ è®­ç»ƒæ—¶çš„tokenåºåˆ—æ ¼å¼:")
        print("   æ–‡æœ¬: [<|im_start|>] + text_tokens + [<|im_end|>]")
        print("   å›¾åƒ: [<|vision_start|>] + image_embeddings + [<|vision_end|>]")
        print("   æ··åˆåºåˆ—: text + [<|vision_start|>] + image + [<|vision_end|>] + text")
        
        return True
        
    except Exception as e:
        print(f"âŒ Tokenä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª ä½ çš„è®­ç»ƒæ•°æ®æ ¼å¼å…¼å®¹æ€§æµ‹è¯•")
    print("="*70)
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        ("ä½ çš„æ•°æ®æ ¼å¼è§£æ", test_your_data_format),
        ("Tokenä¸€è‡´æ€§æ£€æŸ¥", test_token_consistency),
    ]
    
    results = {}
    for test_name, test_func in tests:
        try:
            results[test_name] = test_func()
        except Exception as e:
            print(f"âŒ {test_name}æµ‹è¯•å‡ºç°å¼‚å¸¸: {e}")
            results[test_name] = False
    
    # æ€»ç»“ç»“æœ
    print("\n" + "="*70)
    print("ğŸ æµ‹è¯•ç»“æœæ€»ç»“")
    print("="*70)
    
    passed = 0
    total = len(tests)
    
    for test_name, passed_test in results.items():
        status = "âœ… é€šè¿‡" if passed_test else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
        if passed_test:
            passed += 1
    
    print(f"\næ€»è®¡: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ å®Œç¾ï¼ä½ çš„è®­ç»ƒæ•°æ®æ ¼å¼å®Œå…¨å…¼å®¹ï¼")
        print("\nâœ¨ å…³é”®ç‚¹æ€»ç»“:")
        print("1. ğŸ“ ä½ çš„æ•°æ®æ ¼å¼ (messages + images + <image>æ ‡è®°) å·²å®Œå…¨æ”¯æŒ")
        print("2. ğŸ”— è®­ç»ƒä»£ç ä¼šè‡ªåŠ¨å°†<image>è½¬æ¢ä¸º<|vision_start|>å’Œ<|vision_end|>tokenå¯¹")
        print("3. ğŸ¯ ç»Ÿä¸€åºåˆ—æ ¼å¼ç¡®ä¿äº†ä¸æ¨ç†ä»£ç çš„å®Œå…¨å…¼å®¹")
        print("4. ğŸ’¾ æŸå¤±è®¡ç®—åªåœ¨ç›®æ ‡åºåˆ—ä½ç½®è¿›è¡Œï¼Œé¿å…äº†è¾“å…¥åºåˆ—çš„å¹²æ‰°")
        print("\nğŸš€ ç°åœ¨ä½ å¯ä»¥ç›´æ¥ç”¨ä½ çš„æ•°æ®æ ¼å¼è¿›è¡Œè®­ç»ƒäº†ï¼")
        
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥ã€‚")
    
    print("="*70)


if __name__ == "__main__":
    main()
